{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Directories","metadata":{}},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-13T17:57:42.993190Z","iopub.execute_input":"2023-04-13T17:57:42.993501Z","iopub.status.idle":"2023-04-13T17:57:43.043233Z","shell.execute_reply.started":"2023-04-13T17:57:42.993471Z","shell.execute_reply":"2023-04-13T17:57:43.042092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vids = [\"Video1_Clip1.mp4\", \"Video1_Clip2.mp4\", \"Video1_Clip3.mp4\", \"ShortClip1.mp4\"]\nweight_dirs = [\"/kaggle/input/backup-tnv2/model906_30\", \"/kaggle/input/backup-tnv2/weights_k14_epoch19/weights_k14_epoch19/\"]","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:18:39.297022Z","iopub.execute_input":"2023-04-11T23:18:39.297667Z","iopub.status.idle":"2023-04-11T23:18:39.305100Z","shell.execute_reply.started":"2023-04-11T23:18:39.297628Z","shell.execute_reply":"2023-04-11T23:18:39.303966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Imports and Helper Functions","metadata":{}},{"cell_type":"code","source":"import sys\nimport getopt\nimport numpy as np\nimport os\nfrom glob import glob\nfrom keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.utils import array_to_img\nfrom tensorflow.keras.utils import img_to_array\nfrom tensorflow.keras.utils import load_img\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import *\nfrom keras.layers import *\nimport keras.backend as K\nfrom keras import optimizers\nimport tensorflow as tf\nimport cv2\nfrom os.path import isfile, join\nfrom PIL import Image\nimport time\nimport math","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:18:51.529868Z","iopub.execute_input":"2023-04-11T23:18:51.530179Z","iopub.status.idle":"2023-04-11T23:18:58.902374Z","shell.execute_reply.started":"2023-04-11T23:18:51.530147Z","shell.execute_reply":"2023-04-11T23:18:58.901284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import *\nfrom keras.layers import *\nfrom keras.activations import *\ndef TrackNet3( input_height, input_width ): #input_height = 288, input_width = 512\n\timgs_input = Input(shape=(9,input_height,input_width))\n\t#Layer1\n\tx = Conv2D(64, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(imgs_input)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer2\n\tx = Conv2D(64, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n\tx = ( Activation('relu'))(x)\n\tx1 = ( BatchNormalization())(x)\n\t#Layer3\n\tx = MaxPooling2D((2, 2), strides=(2, 2), data_format='channels_first' )(x1)\n\t#Layer4\n\tx = Conv2D(128, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer5\n\tx = Conv2D(128, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n\tx = ( Activation('relu'))(x)\n\tx2 = ( BatchNormalization())(x)\n\t#x2 = (Dropout(0.5))(x2) \n\t#Layer6\n\tx = MaxPooling2D((2, 2), strides=(2, 2), data_format='channels_first' )(x2)\n\t#Layer7\n\tx = Conv2D(256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer8\n\tx = Conv2D(256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer9\n\tx = Conv2D(256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n\tx = ( Activation('relu'))(x)\n\tx3 = ( BatchNormalization())(x)\n\t#x3 = (Dropout(0.5))(x3)\n\t#Layer10\n\tx = MaxPooling2D((2, 2), strides=(2, 2), data_format='channels_first' )(x3)\n\t#Layer11\n\tx = ( Conv2D(512, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer12\n\tx = ( Conv2D(512, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer13\n\tx = ( Conv2D(512, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#x = (Dropout(0.5))(x)\n\t#Layer14\n\t#x = UpSampling2D( (2,2), data_format='channels_first')(x)\n\tx = concatenate( [UpSampling2D( (2,2), data_format='channels_first')(x), x3], axis=1)\n\t#Layer15\n\tx = ( Conv2D( 256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer16\n\tx = ( Conv2D( 256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer17\n\tx = ( Conv2D( 256, (3, 3), kernel_initializer='random_uniform', padding='same', data_format='channels_first'))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t\n\t#Layer18\n\t#x = UpSampling2D( (2,2), data_format='channels_first')(x)\n\tx = concatenate( [UpSampling2D( (2,2), data_format='channels_first')(x), x2], axis=1)\n\t#Layer19\n\tx = ( Conv2D( 128 , (3, 3), kernel_initializer='random_uniform', padding='same' , data_format='channels_first' ))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer20\n\tx = ( Conv2D( 128 , (3, 3), kernel_initializer='random_uniform', padding='same' , data_format='channels_first' ))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer21\n\t#x = UpSampling2D( (2,2), data_format='channels_first')(x)\n\tx = concatenate( [UpSampling2D( (2,2), data_format='channels_first')(x), x1], axis=1)\n\t#Layer22\n\tx = ( Conv2D( 64 , (3, 3), kernel_initializer='random_uniform', padding='same'  , data_format='channels_first' ))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer23\n\tx = ( Conv2D( 64 , (3, 3), kernel_initializer='random_uniform', padding='same'  , data_format='channels_first' ))(x)\n\tx = ( Activation('relu'))(x)\n\tx = ( BatchNormalization())(x)\n\t#Layer24\n\tx =  Conv2D( 3 , (1, 1) , kernel_initializer='random_uniform', padding='same', data_format='channels_first' )(x)\n\tx = ( Activation('sigmoid'))(x)\n        \n\to_shape = Model(imgs_input , x ).output_shape\n\t#print (\"layer24 output shape:\", o_shape[1],o_shape[2],o_shape[3])\n\t#Layer24 output shape: (3, 288, 512)\n\tOutputHeight = o_shape[2]\n\tOutputWidth = o_shape[3]\n\toutput = x\n\tmodel = Model( imgs_input , output)\n\t#model input unit:9*288*512, output unit:3*288*512\n\tmodel.outputWidth = OutputWidth\n\tmodel.outputHeight = OutputHeight\n\t#Show model's details\n\t#model.summary()\n\treturn model","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:18:58.903807Z","iopub.execute_input":"2023-04-11T23:18:58.904496Z","iopub.status.idle":"2023-04-11T23:18:58.929188Z","shell.execute_reply.started":"2023-04-11T23:18:58.904465Z","shell.execute_reply":"2023-04-11T23:18:58.928090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loss function\ndef custom_loss(y_true, y_pred):\n\tloss = (-1)*(K.square(1 - y_pred) * y_true * K.log(K.clip(y_pred, K.epsilon(), 1)) + K.square(y_pred) * (1 - y_true) * K.log(K.clip(1 - y_pred, K.epsilon(), 1)))\n\treturn K.mean(loss)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:18:58.930880Z","iopub.execute_input":"2023-04-11T23:18:58.931601Z","iopub.status.idle":"2023-04-11T23:18:58.941635Z","shell.execute_reply.started":"2023-04-11T23:18:58.931565Z","shell.execute_reply":"2023-04-11T23:18:58.940687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE=1\nHEIGHT=288\nWIDTH=512","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:18:58.943148Z","iopub.execute_input":"2023-04-11T23:18:58.943506Z","iopub.status.idle":"2023-04-11T23:18:58.951734Z","shell.execute_reply.started":"2023-04-11T23:18:58.943470Z","shell.execute_reply":"2023-04-11T23:18:58.950746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Load in old weights","metadata":{}},{"cell_type":"code","source":"old_model = load_model(weight_dirs[0], custom_objects={'custom_loss':custom_loss})","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:18:58.953166Z","iopub.execute_input":"2023-04-11T23:18:58.953430Z","iopub.status.idle":"2023-04-11T23:19:04.918435Z","shell.execute_reply.started":"2023-04-11T23:18:58.953406Z","shell.execute_reply":"2023-04-11T23:19:04.917374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_trainable_params = np.sum([K.count_params(w) for w in old_model.trainable_weights])\nf\"{num_trainable_params} trainable parameters\"","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:19:04.920473Z","iopub.execute_input":"2023-04-11T23:19:04.921133Z","iopub.status.idle":"2023-04-11T23:19:04.931839Z","shell.execute_reply.started":"2023-04-11T23:19:04.921094Z","shell.execute_reply":"2023-04-11T23:19:04.930677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_non_trainable_params = np.sum([K.count_params(w) for w in old_model.non_trainable_weights])\nf\"{num_non_trainable_params} non-trainable parameters\"","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:19:04.935860Z","iopub.execute_input":"2023-04-11T23:19:04.936121Z","iopub.status.idle":"2023-04-11T23:19:04.944902Z","shell.execute_reply.started":"2023-04-11T23:19:04.936096Z","shell.execute_reply":"2023-04-11T23:19:04.943878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Load in new weights","metadata":{}},{"cell_type":"code","source":"new_model = load_model(weight_dirs[1], custom_objects={'custom_loss':custom_loss})","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:19:04.946630Z","iopub.execute_input":"2023-04-11T23:19:04.946971Z","iopub.status.idle":"2023-04-11T23:19:08.980478Z","shell.execute_reply.started":"2023-04-11T23:19:04.946936Z","shell.execute_reply":"2023-04-11T23:19:08.979419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_trainable_params = np.sum([K.count_params(w) for w in new_model.trainable_weights])\nf\"{num_trainable_params} trainable parameters\"","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:19:08.987683Z","iopub.execute_input":"2023-04-11T23:19:08.988099Z","iopub.status.idle":"2023-04-11T23:19:08.998128Z","shell.execute_reply.started":"2023-04-11T23:19:08.988063Z","shell.execute_reply":"2023-04-11T23:19:08.995970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_non_trainable_params = np.sum([K.count_params(w) for w in new_model.non_trainable_weights])\nf\"{num_non_trainable_params} non-trainable parameters\"","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:19:08.999462Z","iopub.execute_input":"2023-04-11T23:19:09.000490Z","iopub.status.idle":"2023-04-11T23:19:09.022848Z","shell.execute_reply.started":"2023-04-11T23:19:09.000450Z","shell.execute_reply":"2023-04-11T23:19:09.021495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Prediction Function","metadata":{}},{"cell_type":"code","source":"def make_pred_csv(predict_csv_dir, vid_dir, model):\n    start = time.time()\n    f = open(predict_csv_dir, 'w')\n    f.write('Frame,Visibility,X,Y\\n')\n    cap = cv2.VideoCapture(vid_dir)\n    cap.set(1,0) # set to 0'th frame?                            \n    success, image1 = cap.read()\n    success, image2 = cap.read()\n    success, image3 = cap.read()\n    ratio = image1.shape[0] / HEIGHT\n    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    count = 0\n    \n    start_time = time.time()\n    while success:\n        # count is in multiples of 3\n        # report status every 99 frames\n#         if count != 0 and (count/3) % 33 == 0:\n#             end_time = time.time()\n#             elapsed = round(end_time-start_time, 2) # seconds\n#             estimated_total = round((num_frames/count)*(elapsed)/60/60,2) # hours\n#             print(f\"\\t({count}/{num_frames} frames) {elapsed} seconds elapsed, {estimated_total} estimated hours total\")\n\n        unit = []\n        #Adjust BGR format (cv2) to RGB format (PIL)\n        x1 = image1[...,::-1]\n        x2 = image2[...,::-1]\n        x3 = image3[...,::-1]\n        #Convert np arrays to PIL images\n        x1 = array_to_img(x1)\n        x2 = array_to_img(x2)\n        x3 = array_to_img(x3)\n        #Resize the images\n        x1 = x1.resize(size = (WIDTH, HEIGHT))\n        x2 = x2.resize(size = (WIDTH, HEIGHT))\n        x3 = x3.resize(size = (WIDTH, HEIGHT))\n        #Convert images to np arrays and adjust to channels first\n        x1 = np.moveaxis(img_to_array(x1), -1, 0)\n        x2 = np.moveaxis(img_to_array(x2), -1, 0)\n        x3 = np.moveaxis(img_to_array(x3), -1, 0)\n        #Create data\n        unit.append(x1[0])\n        unit.append(x1[1])\n        unit.append(x1[2])\n        unit.append(x2[0])\n        unit.append(x2[1])\n        unit.append(x2[2])\n        unit.append(x3[0])\n        unit.append(x3[1])\n        unit.append(x3[2])\n        unit=np.asarray(unit)\t\n        unit = unit.reshape((1, 9, HEIGHT, WIDTH))\n        unit = unit.astype('float32')\n        unit /= 255\n        y_pred = model.predict(unit, batch_size=BATCH_SIZE, verbose=0)\n        y_pred = y_pred > 0.5\n        y_pred = y_pred.astype('float32')\n        h_pred = y_pred[0]*255\n        h_pred = h_pred.astype('uint8')\n        for i in range(3):\n            if i == 0:\n                image = image1\n            elif i == 1:\n                image = image2\n            elif i == 2:\n                image = image3\n            if np.amax(h_pred[i]) <= 0:\n                f.write(str(count)+',0,-1,-1\\n')\n            else:\n                #h_pred\n                (cnts, _) = cv2.findContours(h_pred[i].copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n                rects = [cv2.boundingRect(ctr) for ctr in cnts]\n                max_area_idx = 0\n                max_area = rects[max_area_idx][2] * rects[max_area_idx][3]\n                for i in range(len(rects)):\n                    area = rects[i][2] * rects[i][3]\n                    if area > max_area:\n                        max_area_idx = i\n                        max_area = area\n                target = rects[max_area_idx]\n                (cx_pred, cy_pred) = (int(ratio*(target[0] + target[2] / 2)), int(ratio*(target[1] + target[3] / 2)))\n                f.write(str(count)+',1,'+str(cx_pred)+','+str(cy_pred)+'\\n')\n            count += 1\n            \n        success, image1 = cap.read()\n        success, image2 = cap.read()\n        success, image3 = cap.read()\n    f.close()\n    end = time.time()\n    print(f\"\\tVideo had {num_frames} frames. Predicted {count} frames. Last {num_frames - count} frames didn't get predicted.\") \n    print(f\"\\tDone in {round(end-start, 2)} seconds\")","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:36:23.986325Z","iopub.execute_input":"2023-04-11T23:36:23.986778Z","iopub.status.idle":"2023-04-11T23:36:24.008460Z","shell.execute_reply.started":"2023-04-11T23:36:23.986742Z","shell.execute_reply":"2023-04-11T23:36:24.007311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***\n# Run prediction function with old and new weights","metadata":{}},{"cell_type":"code","source":"for vid in vids:\n    vid_dir = f\"/kaggle/input/backup-tnv2/{vid}\"\n    for version, model in [(\"old\", old_model), (\"new\", new_model)]:\n        predict_csv_dir = f\"/kaggle/working/{vid[:-4]}_{version}_weights_predict.csv\"\n        print(f\"Predicting {vid} with {version} weights...\")\n        make_pred_csv(predict_csv_dir, vid_dir, model)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T23:36:25.857281Z","iopub.execute_input":"2023-04-11T23:36:25.857969Z","iopub.status.idle":"2023-04-11T23:37:52.856785Z","shell.execute_reply.started":"2023-04-11T23:36:25.857932Z","shell.execute_reply":"2023-04-11T23:37:52.855595Z"},"trusted":true},"execution_count":null,"outputs":[]}]}